{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xavier/projects/godatathon_2020\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.model.nets import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = pd.read_csv(\"data/raw/gx_volume.csv\", index_col=0)\n",
    "submissions = pd.read_csv(\"data/raw/submission_template.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume[\"country_brand\"] = volume[\"country\"] + \"-\" + volume[\"brand\"]\n",
    "submissions[\"country_brand\"] = submissions[\"country\"] + \"-\" + submissions[\"brand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out country/brand in submissions\n",
    "volume = volume[~volume[\"country_brand\"].isin(submissions[\"country_brand\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = volume.sort_values([\"country\", \"brand\", \"month_num\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: In the future, we will compute the loss only on data that we have available for each country/mont\n",
    "# i.e. If a country only has volume until mont 20, we will pad/ignore the loss of months 21-24\n",
    "country_brand_post_count = volume[volume[\"month_num\"] >= 0].groupby(\"country_brand\").size()\n",
    "idx_post_volume_full = country_brand_post_count[country_brand_post_count == 24].index\n",
    "volume = volume[volume[\"country_brand\"].isin(idx_post_volume_full)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = volume.groupby([\"country\", \"brand\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, df in g:\n",
    "    df_pre = df[df[\"month_num\"] < 0]\n",
    "    df_post = df[df[\"month_num\"] >= 0]\n",
    "    \n",
    "    # TODO: Take into consideration scaling\n",
    "    \n",
    "    X = df_pre[\"volume\"]\n",
    "    y = df_post[\"volume\"]   \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X.values)\n",
    "y = torch.from_numpy(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "hidden_dim = 5\n",
    "num_layers = 1\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim, hidden_dim, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_legth = 123 # Number of months (depends on case)\n",
    "\n",
    "encoder_input = torch.randn(input_legth, batch_size, input_dim)\n",
    "\n",
    "# Predict\n",
    "encoder_out, encoder_hidden_out = encoder(encoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input:\t\t torch.Size([123, 16, 1])\n",
      "encoder_out:\t\t torch.Size([123, 16, 10])\n",
      "encoder_hidden_out:\t torch.Size([2, 16, 5])\n"
     ]
    }
   ],
   "source": [
    "print(\"encoder_input:\\t\\t\", encoder_input.shape)\n",
    "print(\"encoder_out:\\t\\t\", encoder_out.shape)\n",
    "print(\"encoder_hidden_out:\\t\", encoder_hidden_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# -1, 0, 1...\n",
    "y_true = torch.tensor([10_000] + [9_000, 7_000, 5_000, 3_000, 1_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = nn.GRU(input_dim, hidden_dim, num_layers, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throw away encoder output\n",
    "_ = encoder_out\n",
    "\n",
    "# Dummy representing month -1\n",
    "decoder_input = torch.randn(1, batch_size, input_dim)\n",
    "# decoder_input = torch.randn(23, batch_size, input_dim)\n",
    "\n",
    "# Using hidden_out from Encoder as hidden_in\n",
    "decoder_hidden_0 = encoder_hidden_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 16, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 10])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out[-1].unsqueeze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_out, decoder_hidden_out = decoder(decoder_input, decoder_hidden_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_input:\t\t torch.Size([23, 16, 1])\n",
      "decoder_hidden_0:\t torch.Size([2, 16, 5])\n",
      "decoder_out:\t\t torch.Size([23, 16, 10])\n",
      "decoder_hidden_out:\t torch.Size([2, 16, 5])\n"
     ]
    }
   ],
   "source": [
    "print(\"decoder_input:\\t\\t\", decoder_input.shape)\n",
    "print(\"decoder_hidden_0:\\t\", decoder_hidden_0.shape)\n",
    "print(\"decoder_out:\\t\\t\", decoder_out.shape)\n",
    "print(\"decoder_hidden_out:\\t\", decoder_hidden_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim, num_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden with zeros\n",
    "        h0 = torch.zeros(self.input_dim, self.batch_size, self.hidden_dim)\n",
    "        output, hn = rnn(input, h0)\n",
    "        return output, hn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
