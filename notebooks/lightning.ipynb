{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.model.trainer import RNNModel\n",
    "from src.model.dataset import NovartisDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3\n",
    "hidden_dim = 30\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 27\n",
    "SEED = 28\n",
    "LR = 1e-3\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "TEST_SIZE = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/features/final_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values([\"country\", \"brand\", \"month_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unknown duplicates\n",
    "df = df.drop_duplicates([\"country\", \"brand\", \"month_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only cases with 24 months after generic (To remove later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: In the future, we will compute the loss only on data that we have available for each country/mont\n",
    "# i.e. If a country only has volume until mont 20, we will pad/ignore the loss of months 21-24\n",
    "country_brand_post_count = df[df[\"month_num\"] >= 0].groupby([\"country\", \"brand\"]).size()\n",
    "\n",
    "country_brand_post_count.name = \"post_months_count\"\n",
    "country_brand_post_count = country_brand_post_count.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(country_brand_post_count, on=[\"country\", \"brand\"], how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only dataset with 24 months after generic\n",
    "df = df[df[\"post_months_count\"]==24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused column\n",
    "df = df.drop(columns=\"post_months_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add country-brand column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"country_brand\"] = df[\"country\"] + \"-\" + df[\"brand\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Val Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country_brands = df[\"country_brand\"].drop_duplicates().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Val split\n",
    "country_brands_train, country_brands_val = train_test_split(country_brands,\n",
    "                                                            test_size=TEST_SIZE,\n",
    "                                                            random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_train = df[df[\"country_brand\"].isin(country_brands_train)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset/DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = NovartisDataset(volume_train)\n",
    "dl_train = DataLoader(ds_train, batch_size=1, num_workers=NUM_WORKERS, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_val = df[df[\"country_brand\"].isin(country_brands_val)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val = NovartisDataset(volume_val)\n",
    "dl_val = DataLoader(ds_val, batch_size=1, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor=\"val/loss\")\n",
    "early_stopping_callback = pl.callbacks.EarlyStopping(monitor=\"val/loss\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trainer = pl.Trainer(max_epochs=50,\n",
    "                     callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "                     accumulate_grad_batches=4,\n",
    "                     gpus=1)\n",
    "model = RNNModel(input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, lr=LR)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trainer.fit(model, train_dataloader=dl_train, val_dataloaders=dl_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"lightning_logs/version_5/checkpoints/epoch=49.ckpt\"\n",
    "model_path = \"lightning_logs/version_8/checkpoints/epoch=13.ckpt\"\n",
    "model_path = \"lightning_logs/version_12/checkpoints/epoch=18.ckpt\"\n",
    "model_path = \"lightning_logs/version_14/checkpoints/epoch=17.ckpt\"\n",
    "model_path = \"lightning_logs/version_15/checkpoints/epoch=37.ckpt\"\n",
    "model_path = \"lightning_logs/version_19/checkpoints/epoch=12.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel.load_from_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/features/final_features.csv\")\n",
    "df[\"country_brand\"] = df[\"country\"] + \"-\" + df[\"brand\"]\n",
    "\n",
    "# Delete unknown duplicates\n",
    "df = df.drop_duplicates([\"country\", \"brand\", \"month_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = pd.read_csv(\"data/raw/submission_template.csv\")\n",
    "submissions[\"country_brand\"] = submissions[\"country\"] + \"-\" + submissions[\"brand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out country/brand in submissions\n",
    "df_test = df[df[\"country_brand\"].isin(submissions[\"country_brand\"])]\n",
    "\n",
    "# Sort values\n",
    "df_test = df_test.sort_values([\"country\", \"brand\", \"month_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = NovartisDataset(df_test)\n",
    "dl_test = DataLoader(ds_test, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_volume_series = df.groupby(\"country_brand\")[\"max_volume\"].unique().apply(lambda x: x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = NovartisDataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "model.eval()\n",
    "for n, batch in enumerate(tqdm(dl_test)):\n",
    "    # Unpack batch\n",
    "    encoder_temp_features = batch[\"encoder_temp_features\"]\n",
    "    encoder_num_features = batch[\"encoder_num_features\"]\n",
    "    encoder_cat_features = batch[\"encoder_cat_features\"]\n",
    "    decoder_temp_features = batch[\"decoder_temp_features\"]\n",
    "    y = batch[\"y_norm\"]\n",
    "    avg_12_volume = batch[\"avg_12_volume\"]\n",
    "    max_volume = batch[\"max_volume\"]\n",
    "\n",
    "    # Permute arrays\n",
    "    encoder_temp_features = encoder_temp_features.permute(1, 0, 2)\n",
    "    y = y.permute(1, 0, 2)\n",
    "\n",
    "    # encoder_num_features = encoder_num_features.permute(1, 0)\n",
    "    encoder_cat_features = encoder_cat_features.permute(1, 0)\n",
    "\n",
    "    # Predict\n",
    "    y_hat = model(encoder_temp_features,\n",
    "                 encoder_num_features,\n",
    "                 encoder_cat_features,\n",
    "                 y)\n",
    "    \n",
    "    \n",
    "    volume_preds = y_hat[\"prediction\"].detach().numpy().flatten()\n",
    "    upper_bounds = y_hat[\"upper_bound\"].detach().numpy().flatten()\n",
    "    lower_bounds = y_hat[\"lower_bound\"].detach().numpy().flatten()\n",
    "\n",
    "    for month in range(24):\n",
    "        country, brand = ds_test.group_keys[n]\n",
    "        \n",
    "        # Add volume scaling\n",
    "        volume_scaling = max_volume_series.loc[country + \"-\" + brand].item()\n",
    "        \n",
    "        # Select month predictions + Scale\n",
    "        vol_pred = volume_preds[month] * volume_scaling\n",
    "        upper_pred = upper_bounds[month] * volume_scaling\n",
    "        lower_pred = lower_bounds[month] * volume_scaling\n",
    "        \n",
    "        # Filter out invalid values\n",
    "        vol_pred = max(vol_pred, 0)\n",
    "        upper_pred = max(upper_pred, vol_pred)\n",
    "        lower_pred = min(max(lower_pred, 0), vol_pred)\n",
    "\n",
    "        prediction = {\"country\": country,\n",
    "                      \"brand\": brand,\n",
    "                      \"month_num\": month,\n",
    "                      \"pred_95_low\": lower_pred,\n",
    "                      \"prediction\": vol_pred,\n",
    "                      \"pred_95_high\": upper_pred}\n",
    "\n",
    "        predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame(predictions)\n",
    "df_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to submissions\n",
    "merge_cols = [\"country\", \"brand\", \"month_num\"]\n",
    "final_submissions = submissions[merge_cols].merge(df_preds, on=merge_cols, how=\"left\")\n",
    "final_submissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = [\"country\", \"brand\", \"month_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submissions = final_submissions.set_index(id_cols)\n",
    "df = df.set_index(id_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for row in tqdm(final_submissions.itertuples()):\n",
    "    if row.Index in df.index:\n",
    "        final_submissions.loc[row.Index] = df.loc[row.Index, \"volume\"]\n",
    "        i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total overwrites:\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submissions.to_csv(\"data/submissions/sumbission_09.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
